{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyPLTbW2N+iDJMEKt/ittfKh",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AugustvonMackensen/AI_colab/blob/main/deeplearning_backpropagation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "[1] Import Packages"
      ],
      "metadata": {
        "id": "zRI6p7y8p4QC"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kFg5XGdCpJfY"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from sklearn.datasets import load_iris"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "[2] Define the functions for the data preparation"
      ],
      "metadata": {
        "id": "MVbFmjgHp7Rz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def prepare_data(target):\n",
        "  iris = load_iris()    # Read iris dataset\n",
        "  X_tr = iris.data[:, 2:]   # Select the bloom's length and width\n",
        "  labels = iris.target_names\n",
        "  y = iris.target\n",
        "\n",
        "  # Set Label for the samples : If label is targeted then 1, else 0\n",
        "  y_tr = []\n",
        "  for i in range(150):\n",
        "    y_tr.append(labels[y[i]] == target)\n",
        "  y_tr = np.array(y_tr, dtype=int)\n",
        "  return X_tr, y_tr, ['(1) ' + target, '(0) the others']"
      ],
      "metadata": {
        "id": "WPMuWdebqBMR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "[3] Sigmoid"
      ],
      "metadata": {
        "id": "zrT6hMEEqyJa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def sigmoid(x):\n",
        "  ''' x : numpy array'''\n",
        "  return 1 / (1 + np.exp(-x))"
      ],
      "metadata": {
        "id": "hBHogqOPq5dK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "[4] Loss : Mse, Cross Entropy"
      ],
      "metadata": {
        "id": "Du6sDUM9rNj5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get Loss Mse\n",
        "def loss_mse(y, y_hat):\n",
        "  loss = 0.0\n",
        "  for i in range(len(y)):\n",
        "    err = y_hat[i] - y[i]\n",
        "    loss += np.dot(err, err)\n",
        "  return loss / len(y)\n",
        "\n",
        "#Get Loss Ce\n",
        "def loss_ce(y, y_hat):\n",
        "  loss = 0.0\n",
        "  if len(y.shape) == 1 or y.shape[1] == 1:\n",
        "    for i in range(len(y)):\n",
        "      loss += -(y[i] * np.log(y_hat[i]) + (1-y[i]) * np.log((1-y.hat[i]))).sum()\n",
        "  else:\n",
        "    for i in range(len(y)):\n",
        "      loss += -(y[i] * np.log(y_hat[i])).sum()\n",
        "  return loss/len(y)"
      ],
      "metadata": {
        "id": "JMYFfOEKrQ76"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "[5] Dense Class"
      ],
      "metadata": {
        "id": "V2J2brXzuCUK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Dense():\n",
        "  def __init__(self, nIn, nOut, activation='sigmoid', loss='mse'):\n",
        "    self.nIn = nIn      # the number of inputs\n",
        "    self.nOut = nOut    # the number of outputs\n",
        "\n",
        "    # initialize the weight and bias by using He normal\n",
        "    rnd = np.random.default_rng()\n",
        "    self.w = rnd.normal(scale=np.sqrt(2.0 / self.nIn), size = (self.nOut, self.nIn)).astype(np.float32)\n",
        "    self.b = rnd.normal(scale=np.sqrt(2.0 / self.nIn), size = self.nOut).astype(np.float32)\n",
        "\n",
        "    # Set Activation Function\n",
        "    if activation == 'sigmoid':\n",
        "      self.activation = sigmoid\n",
        "      if loss == 'ce': self.dE_du = self.dE_du_sigmoid_ce\n",
        "      else:            self.dE_du = self.dE_du_sigmoid_mse\n",
        "      self.do_du = self.do_du_sigmoid\n",
        "\n",
        "    # Set Initial Value for Velocity to apply Momentum\n",
        "    self.velocity_w, self.velocity_b = 0.0, 0.0\n",
        "\n",
        "  # Calculate output in terms of input X\n",
        "  def output(self, X):\n",
        "    self.in_vec = X   # Store the input for bp\n",
        "    # Calculate the sum of weights\n",
        "    u = np.array([np.dot(self.w[i], X) + self.b[i] for i in range(self.nOut)], dtype=np.float32)\n",
        "\n",
        "    # Calculate output by applying activation\n",
        "    self.out_vec = self.activation(u) # store the Output for bp\n",
        "    return self.out_vec\n",
        "\n",
        "  # Update w and b by following Gradient Descent\n",
        "  def gd(self, dw, db, momentum=0):\n",
        "    self.velocity_w = self.velocity_w * momentum - dw\n",
        "    self.velocity_b = self.velocity_b * momentum - db\n",
        "    self.w += self.velocity_w\n",
        "    self.b += self.velocity_b\n",
        "\n",
        "  def dE_du_sigmoid_mse(self, y):\n",
        "    return (self.out_vec - y) * self.do_du_sigmoid()\n",
        "\n",
        "  def dE_du_sigmoid_ce(self, y):\n",
        "    return self.out_vec - y\n",
        "\n",
        "  def do_du_sigmoid(self):\n",
        "    return self.out_vec * (1 - self.out_vec)\n"
      ],
      "metadata": {
        "id": "N3MkBBQru7DB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "[6] BP Model Class : FeedForward Model Class for BP learning"
      ],
      "metadata": {
        "id": "0gudV5jAodOi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class BP_Model():\n",
        "  def __init__(self, nUnitLst, loss='mse', activation_h='sigmoid', activation_o='sigmoid'):\n",
        "    layers = []\n",
        "    self.nLayers = len(nUnitLst) - 1\n",
        "\n",
        "    # Generate Hidden Layer\n",
        "    for i in range(self.nLayers - 1):\n",
        "      layers.append(Dense(nUnitLst[i], nUnitLst[i+1], activation=activation_h, loss=loss))\n",
        "\n",
        "    # Generate Output Layer\n",
        "    layers.append(Dense(nUnitLst[self.nLayers-1], nUnitLst[self.nLayers], activation=activation_o, loss=loss))\n",
        "    self.layers = np.array(layers, dtype=object)\n",
        "    self.ohe = np.identity(nUnitLst[-1])\n",
        "    if loss == 'ce':\n",
        "      self.loss = loss_ce\n",
        "    else:\n",
        "      self.loss =loss_mse\n",
        "\n",
        "  def predict(self, x):\n",
        "    res = []\n",
        "    for j in range(len(x)):\n",
        "      xx = x[j]\n",
        "      for i in range(self.nLayers):\n",
        "        xx = self.layers[i].output(xx)\n",
        "      res.append(xx)\n",
        "    return np.array(res)\n",
        "\n",
        "  def fit(self, X, y, N, epochs, eta=0.01, momentum=0):\n",
        "    # Shuffle the index of learning samples randomly\n",
        "    idx = list(range(N))\n",
        "    np.random.shuffle(idx)\n",
        "    X = np.array([X[idx[i]] for i in range(N)])\n",
        "    if self.layers[self.nLayers-1].nOut == 1:\n",
        "      y = np.array([[y[idx[i]]] for i in range(N)])\n",
        "    else:\n",
        "      y = np.array([self.ohe[y[idx[i]]] for i in range(N)])\n",
        "\n",
        "    f = 'Epochs = {:4d}   Loss = {:8.5f}'\n",
        "    # Prepared to store changing values of w and b\n",
        "    dw, db = [], []\n",
        "    for i in range(self.nLayers):\n",
        "      dw.append(np.zeros((self.layers[i].nOut, self.layers[i].nIn),\n",
        "                          dtype=np.float32))\n",
        "      db.append(np.zeros(self.layers[i].nOut, dtype=np.float32))\n",
        "    for n in range(epochs):\n",
        "      for m in range(N):\n",
        "        # output layer\n",
        "        iCurrLayer = self.nLayers - 1\n",
        "        currLayer = self.layers[iCurrLayer]\n",
        "        self.predict([X[m]])\n",
        "        delta = currLayer.dE_du(y[m])\n",
        "        du_dw = currLayer.in_vec\n",
        "        for j in range(currLayer.nOut):\n",
        "          dw[iCurrLayer][j] = eta * delta[j] * du_dw\n",
        "          db[iCurrLayer][j] = eta * delta[j]\n",
        "        nextDelta = delta\n",
        "        nextLayer = currLayer\n",
        "\n",
        "        # hidden layers\n",
        "        for iCurrLayer in range(self.nLayers-2, -1, -1):\n",
        "          currLayer = self.layers[iCurrLayer]\n",
        "          dE_do = []\n",
        "          for n0 in range(currLayer.nOut):\n",
        "            sDeltaW = nextDelta * nextLayer.w[:, n0]\n",
        "            dE_do.append(sDeltaW.sum())\n",
        "          delta = dE_do * currLayer.do_du()\n",
        "          du_dw = currLayer.in_vec\n",
        "          for j in range(currLayer.nOut):\n",
        "            dw[iCurrLayer][j] = eta * delta[j] * du_dw\n",
        "            db[iCurrLayer][j] = eta * delta[j]\n",
        "          nextDelta = delta\n",
        "          nextLayer = currLayer\n",
        "\n",
        "          for i in range(self.nLayers):\n",
        "            self.layers[i].gd(dw[i], db[i])\n",
        "\n",
        "          # Print the learning process\n",
        "          if n < 10 or (n+1) % 100 == 0:\n",
        "            y_hat = self.predict(X)\n",
        "            print(f.format(n+1, self.loss(y, y_hat)))"
      ],
      "metadata": {
        "id": "mv27Z2rsq5EK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "[7] Visualize the Model"
      ],
      "metadata": {
        "id": "H7KdLe3G7GOV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def visualize(net, X, y, multi_class, labels, class_id, colors,\n",
        "             xlabel, ylabel, legend_loc='lower right'):\n",
        "  # list the range between min and max, the gap is 0.05\n",
        "  x_max = np.ceil(np.max(X[:, 0])).astype(int)\n",
        "  x_min = np.floor(np.min(X[:, 0])).astype(int)\n",
        "  y_max = np.ceil(np.max(X[:, 1])).astype(int)\n",
        "  y_min = np.floor(np.min(X[:, 1])).astype(int)\n",
        "  x_lin = np.linspace(x_min, x_max, (x_max-x_min)*20+1)\n",
        "  y_lin = np.linspace(y_min, y_max, (y_max-y_min)*20+1)\n",
        "\n",
        "  # find x and y from the x_lin and y_Lin\n",
        "  x_mesh, y_mesh = np.meshgrid(x_lin, y_lin)\n",
        "\n",
        "  # input\n",
        "  X_test = np.column_stack([x_mesh.ravel(), y_mesh.ravel()])\n",
        "\n",
        "  # calculate output in terms of X_test\n",
        "  if multi_class:\n",
        "    y_hat = net.predict(X_test)\n",
        "    y_hat = np.array([np.argmax(y_hat[k]) for k in range(len(y_hat))], dtype=int)\n",
        "  else:\n",
        "    y_hat = (net.predict(X_test) >= 0.5).astype(int)\n",
        "    y_hat = y_hat.reshape(len(y_hat))\n",
        "\n",
        "  # Set the legend and color for each classes and horizontial and vertical range\n",
        "  plt.xlim(x_min, x_max)\n",
        "  plt.ylim(y_min, y_max)\n",
        "\n",
        "  # draw the Scatter Plot\n",
        "  for c, i, c_name in zip(colors, labels, class_id):\n",
        "    # Scatter Plot for grid coodrinate\n",
        "    plt.scatter(X_test[y_hat == i, 0], X_test[y_hat == i, 1],\n",
        "                c=c, s=5, alpha=0.3, edgecolors='none')\n",
        "    # Scatter Plot for learning samples\n",
        "    plt.scatter(X[y==i, 0], X[y==i, 1],\n",
        "                c=c, s=20, label=c_name)\n",
        "\n",
        "  # set the position for legend\n",
        "  plt.legend(loc=legend_loc)\n",
        "  # print graph after setting label for x-axis and y-axis\n",
        "  plt.xlabel(xlabel, size=12)\n",
        "  plt.ylabel(ylabel, size=12)\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "EoNZqSKr7IS2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "[8] Preparing for train data"
      ],
      "metadata": {
        "id": "PJ-riZhV7THV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nSamples = 150\n",
        "nDim = 2\n",
        "target = 'versicolor' # Set the flower\n",
        "X_tr, y_tr, labels = prepare_data(target)"
      ],
      "metadata": {
        "id": "iJuqPRfx7W2d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "[9] Generate BP_Model and Learning"
      ],
      "metadata": {
        "id": "8p0KeE1Y7fjO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "bp_iris = BP_Model([nDim, 4, 1], loss='mse',\n",
        "                   activation_h='sigmoid', activation_o='sigmoid')\n",
        "bp_iris.fit(X_tr, y_tr, nSamples, epochs=1000, eta=0.1, momentum=0.9)"
      ],
      "metadata": {
        "id": "Kr1BZDpA7i61"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "[10] Visualize Certain Area"
      ],
      "metadata": {
        "id": "5kG69dym-MmN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "visualize(bp_iris, X_tr, y_tr, multi_class=False,\n",
        "          class_id=labels, labels=[1,0], colors=['magenta', 'blue'],\n",
        "          xlabel='petal length', ylabel='petal width')"
      ],
      "metadata": {
        "id": "xQcLfAxy-QIF"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}