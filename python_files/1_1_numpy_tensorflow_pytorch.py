# -*- coding: utf-8 -*-
"""1_1_numpy_tensorflow_pytorch.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1nmICYzss6Y9QymwgEa_uCa2pQuNstTD3

# **1_1_numpy_tensorflow_pytorch.ipynb****
"""

# Pytorch 설치 전 : 런타임 메뉴 > 런타임 유형 변경 > GPU 지정
# Pytorch 설치 (매 세션마다 설치 필요함)
!pip3 install torch
!pip3 install torchvision

"""# **패키지 비교**
- Numpy vs Tensorflow vs PyTorch
- output = x * y +z
"""

import numpy as np
from datetime import datetime

start = datetime.now()

np.random.seed(0) # 랜덤값 발생 고정시킴

N, D  = 3, 4

x = np.random.randn(N,D) # 3행 4열 배열에 0~1 사이의 실수형 랜덤값을 채움
y = np.random.randn(N,D)
z = np.random.randn(N,D)


a = x * y
b = a * z
c = np.sum(b)

grad_c = 1.0
grad_b = grad_c * np.ones((N,D))
grad_a = grad_b.copy()
grad_z = grad_b.copy()
grad_y = grad_a * y
grad_x = grad_a * x

print(grad_x)
print(grad_y)
print(grad_z)

print('연산 처리 시간 : ', datetime.now() - start)

"""Tensorflow는 graph로 연산(operator)를 나타내는 시스템이며, 연산을 하려면 Session 상에서 실행되어야 한다.<br>
Session은 graph(연산을 구성하는 노드) 작업을 cpu나 gpu같은 device에 배정하고 실행을 위한 메소드들을 제공한다.
"""

from tensorflow.python.ops.array_ops import zeros
import tensorflow as tf
import numpy as np
from datetime import datetime

#tf.placeholder() 함수 AttributeError 발생시 해결 방법
# tensorflow 2.0에서는 사용 못 함
import tensorflow.compat.v1 as tf
tf.disable_v2_behavior()
# ----------------------------------------------------------------------------
start = datetime.now()

# 실행 동작을 미리 정의해 놓음
with tf.device('/gpu:0'): # 실행시 gpu 0 사용을 지정함
  x = tf.placeholder(tf.float32) # 나중에 값을 넣을 공간을 만듦
  y = tf.placeholder(tf.float32)
  z = tf.placeholder(tf.float32)

  a = x * y # x[0][0] 값 * y[0][0], x[0][1] * y[0][1], ...... 
  b = a * z
  c = tf.reduce_sum(b) # 배열의 모든 값들의 합계를 구함.

grad_x, grad_y, grad_z = tf.gradients(c, [x, y, z])

# 준비된 공간에 값을 채우는 설정
with tf.Session() as sess:
  values = {
      x: np.random.randn(N, D),
      y: np.random.randn(N, D),
      z: np.random.randn(N, D)
  }

  out = sess.run([c, grad_x, grad_y, grad_z], feed_dict = values)
  c_val, grad_x_val, grad_y_val, grad_z_val = out

print(grad_x_val)
print(grad_y_val)
print(grad_z_val)

print('연산 처리 시간 : ', datetime.now() - start)

import torch
from torch.autograd import Variable
from datetime import datetime

start = datetime.now()

N, D = 3 ,4

# 자동 미분 계산 함수 : autograd.Variable
x = Variable(torch.randn(N, D).cuda(), requires_grad = True)
y = Variable(torch.randn(N, D).cuda(), requires_grad = True)
z = Variable(torch.randn(N, D).cuda(), requires_grad = True)

a = x * y
b = a * z
c = torch.sum(b)

# gradient(경사도) 자동 계산 수행
# 기울기(gradient)가 1.0이라고 가정하고 최종 값인 c에서
# backward를 통해 역전파를 해 줌.
c.backward(gradient=torch.tensor(1, dtype=torch.float))

print(x.grad)
print(y.grad)
print(z.grad)

print('연산 처리 시간 : ', datetime.now() - start)