{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOUGptgYwL7BCYjuNcdg6V3",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AugustvonMackensen/AI_colab/blob/main/tensor_calculation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "텐서(tensor) : 동일한 자료형의 데이터를 저장하는 다차원 배열을 의미함\n",
        "벡터는 1차원 텐서, 행렬은 2차원 텐서로 표현함.\n",
        "텐서는 다차원 배열과 스칼라 값을 표현할 수 있다.\n",
        "\n",
        "텐서는 자료형을 저장할 수 있는 가장 빠른 장치에 저장할 수 있게 함으로써 성능을 높일 수 있음"
      ],
      "metadata": {
        "id": "Xv2oUnzDSE_Q"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "LsLuhrqwHKRA"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "상수 텐서"
      ],
      "metadata": {
        "id": "sm6Db70rQuVW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "a = tf.constant(10.)\n",
        "b = tf.constant([1, 2, 3, 4])\n",
        "c = tf.constant([[[1, 2], [3, 4], [5, 6]],\n",
        "                 [[7, 8], [9, 10], [11, 12]],\n",
        "                [[13, 14], [15, 16], [17, 18]],\n",
        "                [[19, 20], [21, 22], [23, 24]]], dtype=tf.float32)\n",
        "print('a : dtype = ', a.dtype, '\\n', a)\n",
        "print('b : shape = ', b.shape, '\\n', b)\n",
        "print('c : device = ', c.device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NxMmgyXEQwOe",
        "outputId": "16bc85bd-a6ba-43d5-bf8e-db0ffecb37f4"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "a : dtype =  <dtype: 'float32'> \n",
            " tf.Tensor(10.0, shape=(), dtype=float32)\n",
            "b : shape =  (4,) \n",
            " tf.Tensor([1 2 3 4], shape=(4,), dtype=int32)\n",
            "c : device =  /job:localhost/replica:0/task:0/device:GPU:0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "변수 텐서"
      ],
      "metadata": {
        "id": "UmiwZfszSSjg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = tf.Variable(10.)\n",
        "y = tf.Variable([[1., 2., 3.], [4., 5., 6.]])\n",
        "z = np.array([[1., 3.], [2., 4.], [3., 5.]], dtype=np.float32)\n",
        "print('x : dtype = ', x.dtype, '\\n', x)\n",
        "print('y : shape =', y.shape, '\\n', y)\n",
        "print('y : device = ', y.device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sYmLHT1hSUFv",
        "outputId": "7645006a-4395-4b35-d545-c155b2e8e0e1"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x : dtype =  <dtype: 'float32'> \n",
            " <tf.Variable 'Variable:0' shape=() dtype=float32, numpy=10.0>\n",
            "y : shape = (2, 3) \n",
            " <tf.Variable 'Variable:0' shape=(2, 3) dtype=float32, numpy=\n",
            "array([[1., 2., 3.],\n",
            "       [4., 5., 6.]], dtype=float32)>\n",
            "y : device =  /job:localhost/replica:0/task:0/device:GPU:0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "변수 텐서에 값 대입하기"
      ],
      "metadata": {
        "id": "8Oxr-2KcUXq2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x.assign_add(20.) # assign_add : += 연산자의 역할을 함.\n",
        "print('x = ', x.numpy())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5jaxvml0UaZ2",
        "outputId": "dc9ea9e9-aba7-47ac-fd1a-f34239f87647"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x =  30.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "텐서에 대한 산술 연산 및 수학 함수"
      ],
      "metadata": {
        "id": "qI0FV9uNWo0v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print('a * b = ', (a * tf.cast(b, tf.float32)).numpy())\n",
        "print('tf.math.exp(y) = ', tf.exp(y))\n",
        "print('tf.math.reduce_sum(c, axis=2) = ', tf.reduce_sum(c, axis=2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8JJOO__JWrHw",
        "outputId": "a4b2aca0-e9b8-48e0-e4aa-162c3383a390"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "a * b =  [10. 20. 30. 40.]\n",
            "tf.math.exp(y) =  tf.Tensor(\n",
            "[[  2.7182817   7.389056   20.085537 ]\n",
            " [ 54.59815   148.41316   403.4288   ]], shape=(2, 3), dtype=float32)\n",
            "tf.math.reduce_sum(c, axis=2) =  tf.Tensor(\n",
            "[[ 3.  7. 11.]\n",
            " [15. 19. 23.]\n",
            " [27. 31. 35.]\n",
            " [39. 43. 47.]], shape=(4, 3), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "tf.math.exp : e^x의 값을 구한다. tf.math들의 함수들은 tf.math 생략 가능\n",
        "\n",
        "reduce_sum : c의 axis=2에 대해 reduce_sum을 구한다. c[i, j, :]에 대한 합계를 각각의 i,j에 대해 축소(reduction) 연산자 이용해 계산함.\n",
        "\n",
        "행렬에 대한 선형대산 연산이 필요하면 tf.linalg 모듈에서 제공하는 다양한 함수 사용 가능\n",
        "\n",
        "텐서에 대한 연산에 numpy 배열이 사용되었다면 이를 텐서로 묵시적인 형 변환을 하여 처리함.\n",
        "\n",
        "역으로 numpy 배열을 위한 연산에 텐서가 사용되면 텐서를 묵시적으로 numpy 배열로 형 변환을 하여 처리함."
      ],
      "metadata": {
        "id": "pBaqeRHhgLP2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print('tf.linalg.matmul(y,z) = ')\n",
        "print(tf.matmul(y, z))\n",
        "print('np.matmul(y, z) = ')\n",
        "print(np.matmul(y, z))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lDd0M_vihFD-",
        "outputId": "2aa13806-7b9f-4b65-8f42-1ad3966279c4"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.linalg.matmul(y,z) = \n",
            "tf.Tensor(\n",
            "[[14. 26.]\n",
            " [32. 62.]], shape=(2, 2), dtype=float32)\n",
            "np.matmul(y, z) = \n",
            "[[14. 26.]\n",
            " [32. 62.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "자동 미분\n",
        "\n",
        "딥러닝 모델의 역전파 학습은 가중치와 바이어스 등 여러 가지 학습 요소에 대한 손실함수의 편미분을 계산해야 함\n",
        "\n",
        "자동 미분을 이용하면, 모델을 설계한 후 가중치 등 훈련 대상에 대한 편미분을 하는 수식을 직접 유도하지 않아도 됨으로 매우 편리함\n",
        "\n",
        "자동 미분을 하려면 정방향 진행(forward pass)동안 어떠한 연산이 이루어지는지를 기억했다가 역방향 진행(backward pass)를 하는 동안 연산을 역으로 거슬러 올라가는 과정이 필요함.\n",
        "\n",
        "텐서플로는 tf.GradientTape API를 통해 이러한 과정을 처리하는데, tf.GradientTape 의 문맥을 생성 후 정방향 진행의 연산을 테이프에 기록하고, 이 테이프를 되감기하여 미분을 계산함. 이 때 테이프의 watch 메소드를 추적할 텐서를 지정\n",
        "\n",
        "단, trainable 속성이 True(변수 텐서의 디폴트 값)인 변수 텐서는 기본적으로 추적 대상이므로 watch 메소드로 지정하지 않아도 됨\n",
        "tf.GradientTape의 gradient 메소드를 사용하면 테이프에 기록된 연산 사용하여 편미분 계산 가능."
      ],
      "metadata": {
        "id": "Vatz9eIPiKZ-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x1 = tf.Variable(3.)\n",
        "x2 = tf.Variable(1., trainable=False)\n",
        "with tf.GradientTape() as t:\n",
        "  t.watch(x2)\n",
        "  y = (x1 + 2 * x2) ** 2\n",
        "dy_dx = t.gradient(y, [x1, x2]) # (x1 + 2 * x2)^2에 대한 편미분을 구함\n",
        "print(f'dy/dx1 = {dy_dx[0]}') # x1에 대한 편미분\n",
        "print(f'dy/dx2 = {dy_dx[1]}') # x2에 대한 편미분"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Tj2PYRUmU3e",
        "outputId": "c2517acc-af1d-4f34-d6f6-c9f6a802319a"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dy/dx1 = 10.0\n",
            "dy/dx2 = 20.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "자동 미분을 이용한 선형회귀 문제 학습"
      ],
      "metadata": {
        "id": "vejjCQNgx0bQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = tf.constant([1., 3., 5., 7.]) # 독립변수(상수 텐서)\n",
        "y = tf.constant([2., 3., 4., 5.]) # 종속변수(상수 텐ㅅ)\n",
        "w = tf.Variable(1.) # 학습할 파라미터(변수 텐서)\n",
        "b = tf.Variable(0.5) # 학습할 파라미터(변수 텐서)\n",
        "learning_rate = 0.01 # 학습률\n",
        "epochs = 1000 # 반복 횟수"
      ],
      "metadata": {
        "id": "_qk3-0nDyA2r"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "학습 단계 처리 함수 정의"
      ],
      "metadata": {
        "id": "29vdgFIoyyMp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_step(x, y):\n",
        "  with tf.GradientTape() as t:\n",
        "    y_hat = w * x + b\n",
        "    loss = (y_hat - y) ** 2\n",
        "    grads = t.gradient(loss, [w, b])\n",
        "    w.assign_sub(learning_rate * grads[0])\n",
        "    b.assign_sub(learning_rate * grads[1])"
      ],
      "metadata": {
        "id": "3IkZf5BdzB8_"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "w, b 학습시 손실함수를 w,b에 대해 각각 편미분을 구한 다음 학습률을 곱한 값을 기존의 w와 b에서 빼는 과정 반복\n",
        "\n",
        "여기 코드에서는 손실함수는 오차 제곱으로 정의되었다."
      ],
      "metadata": {
        "id": "2zPQD57JznEY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "학습표본 집합에 대한 반복 학습"
      ],
      "metadata": {
        "id": "AXy3jWcMz20o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(epochs):\n",
        "  for k in range(len(y)):\n",
        "    train_step(x[k], y[k])"
      ],
      "metadata": {
        "id": "Y_KIkO1Wz5q3"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "학습된 파라미터 출력"
      ],
      "metadata": {
        "id": "ZhjtjnH90D9u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print('w : {:8.5f}    b: {:8.5f}'.format(w.numpy(), b.numpy()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w45W-VdO0M84",
        "outputId": "145d7ce0-c438-4059-971e-fe720ae999c4"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "w :  0.50000    b:  1.50000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "학습된 파라미터를 이용한 모델 실행"
      ],
      "metadata": {
        "id": "B7A71fxZ0eEY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "f = 'x:{:8.5f}  -->   y:{:8.5f}'\n",
        "for k in range(len(y)):\n",
        "  y_hat = w * x[k] + b\n",
        "  print(f.format(x[k].numpy(), y_hat.numpy()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k5Y3wfWv0giH",
        "outputId": "65552f58-37e7-46c8-995c-c4cd9aa881cf"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x: 1.00000  -->   y: 2.00000\n",
            "x: 3.00000  -->   y: 3.00000\n",
            "x: 5.00000  -->   y: 4.00000\n",
            "x: 7.00000  -->   y: 5.00000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**그래프 실행 모드(graph execution)**\n",
        "\n",
        "딥러닝 모델을 표현하게 되는 경우 즉시 실행 모드에서는 명령 단위로 텐서플로 연산을 실행하여 결과를 파이썬으로 가져오는 과정을 반복함으로써 많은 시간을 소비하게 됨\n",
        "\n",
        "그래프 실행 모드는 데이터 흐름 형태로 표현되는 계산 구조를 나타내는 텐서플로 그래프(tf.graph)를 실행하는 방식으로 동작됨.\n",
        "\n",
        "그래프는 사용 가능한 하드웨어에서 효율적으로 실행하도록 최적화하여 컴파일되므로 그래프를 실행하면 계산을 빠르게 할 수 있고, 병렬처리 활용할 수 있고, 다수의 장치에서 효율적으로 동작하게 만들 수 있다는 장점이 있음\n",
        "\n",
        "특히 대규모 모델, 방대한 양의 데잍에 대해 반복 훈련을 하는 경우 실행 속도 및 메모리 사용 측면에서 더 우수한 성능을 발휘함.\n",
        "\n",
        "자동적으로 그래프로 변환하여 그래프 실행 모드를 동작하게 하려면 tf.function(파이썬 코드를 파이썬에 독립적인 그래프로 변환하는 도구)를 호출하는데, 직접 호출 방식과 수식어로 사용되는 두 가지 방법이 있음.\n",
        "\n",
        "1) 직접 호출 방식 : 일반적 파이썬 함수를 인수로 전달하여 tf.function 호출\n",
        "tf.function은 그 결과를 파이썬이 호출할 수 있는 함수로 변환하여 돌려줌.\n",
        "이 함수를 원래 함수를 사용하듯 사용하면 됨.\n",
        "\n",
        "2)수식어 사용 방법 : @tf.function 으로 사용."
      ],
      "metadata": {
        "id": "vX3bECMn0-2Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "@tf.function\n",
        "def train_step2(x, y):\n",
        "  with tf.GradientTape() as t:\n",
        "    y_hat = w * x + b\n",
        "    loss = (y_hat - y) ** 2\n",
        "    grads = t.gradient(loss, [w, b])\n",
        "    w.assign_sub(learning_rate * grads[0])\n",
        "    b.assign_sub(learning_rate * grads[1])"
      ],
      "metadata": {
        "id": "9DiSjvRa5f5T"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_step_graph = tf.function(train_step2)\n",
        "for i in range(epochs):\n",
        "  for k in range(len(y)):\n",
        "    train_step_graph(x[k], y[k])"
      ],
      "metadata": {
        "id": "mjmZIPmn5wxZ"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('w : {:8.5f}    b: {:8.5f}'.format(w.numpy(), b.numpy()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0WyMqu3s6Drj",
        "outputId": "1267a2cb-4d6d-4439-958c-66546d507047"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "w :  0.50000    b:  1.50000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "f = 'x:{:8.5f}  -->   y:{:8.5f}'\n",
        "for k in range(len(y)):\n",
        "  y_hat = w * x[k] + b\n",
        "  print(f.format(x[k].numpy(), y_hat.numpy()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VxnZvv4b6G-w",
        "outputId": "5eacf4cd-04f3-4ad5-f9cf-2ff1df82df22"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x: 1.00000  -->   y: 2.00000\n",
            "x: 3.00000  -->   y: 3.00000\n",
            "x: 5.00000  -->   y: 4.00000\n",
            "x: 7.00000  -->   y: 5.00000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "결과 분석 : 즉시 실행 모드에 비해 빠르게 실행되는 것을 확인할 수 있었음,"
      ],
      "metadata": {
        "id": "OR-Tv7XP6KKg"
      }
    }
  ]
}